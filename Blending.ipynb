{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os.path as path\n",
    "\n",
    "import threshold\n",
    "import perspective_transform as ptran\n",
    "%matplotlib qt\n",
    "%matplotlib inline\n",
    "import camera_calibration as camcal\n",
    "src = np.float32([[433, 563], [866, 563], [1041, 675], [280, 675]])\n",
    "dst = np.float32([[280, 565], [1042, 563], [1041, 675], [280, 675]])\n",
    "mtx, dist = camcal.calibrate('camera_cal/calibration*.jpg', 9, 6)\n",
    "M, Minv = ptran.get_matrix(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = mpimg.imread('test_images/test2.jpg')\n",
    "undistorted = camcal.undistort(test_img, mtx, dist)\n",
    "warped = ptran.unwarp(undistorted, mtx, dist, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'COLOR_RGB2HSL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-311-0b291ee7cbb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mundistorted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_RGB2HSL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mhls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNORM_MINMAX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCV_32F\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'COLOR_RGB2HSL'"
     ]
    }
   ],
   "source": [
    "hls = cv2.cvtColor(undistorted, cv2.COLOR_RGB2HLS)\n",
    "hls = cv2.normalize(hls, None, alpha = 0, beta = 1, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "H = np.zeros_like(hls[:,:,0])\n",
    "L = np.zeros_like(hls[:,:,1])\n",
    "S = np.zeros_like(hls[:,:,2])\n",
    "\n",
    "Blend = np.zeros_like(hls)\n",
    "Target = np.zeros_like(hls)\n",
    "\n",
    "hls_rgb = \n",
    "\n",
    "saturation = np.mean(hls[:,:,2])\n",
    "print(saturation)\n",
    "# if saturation > 0.20:\n",
    "#     L[hls[:,:,1] > 0.93] = 1\n",
    "#     H[hls[:,:,0] > 0.5] = 1 # L channel threshold\n",
    "#     S[hls[:,:,2] > 0.4] = 1 # S channel threshold\n",
    "#     Target = cv2.cvtColor(S,cv2.COLOR_GRAY2RGB)\n",
    "#     Blend = cv2.cvtColor(H,cv2.COLOR_GRAY2RGB)\n",
    "#     Composite = 1 - (1-Target) * (1-Blend) + np.absolute(Blend-Target)\n",
    "# elif (saturation < 0.16) & (saturation > 0.20) :\n",
    "#     L[hls[:,:,1] > 0.93] = 1 # L channel threshold\n",
    "#     S[hls[:,:,2] > 0.7] = 1 # S channel threshold\n",
    "#     Target = cv2.cvtColor(S,cv2.COLOR_GRAY2RGB)\n",
    "#     Blend = cv2.cvtColor(L,cv2.COLOR_GRAY2RGB)\n",
    "#     Composite = 1 - (1-Target) * (1-Blend)\n",
    "# elif (saturation < 0.16) & (saturation > 0.15):\n",
    "#     print('this1')\n",
    "#     L[hls[:,:,1] > 0.7] = 1 # L channel threshold\n",
    "#     S[hls[:,:,2] > 0.4] = 1 # S channel threshold\n",
    "#     Target = cv2.cvtColor(S,cv2.COLOR_GRAY2RGB)\n",
    "#     Blend = cv2.cvtColor(L,cv2.COLOR_GRAY2RGB)\n",
    "#     Composite = 1 - (1-Target) * (1-Blend)\n",
    "# else:\n",
    "#     print('this2')\n",
    "#     L[hls[:,:,1] > 0.7] = 1 # L channel threshold\n",
    "#     S[hls[:,:,2] > 0.4] = 1 # S channel threshold\n",
    "#     Target = cv2.cvtColor(S,cv2.COLOR_GRAY2RGB)\n",
    "#     Blend = cv2.cvtColor(L,cv2.COLOR_GRAY2RGB)\n",
    "#     Composite = 1 - (1-Target) * (1-Blend)\n",
    "\n",
    "Target = cv2.cvtColor(L,cv2.COLOR_GRAY2RGB)\n",
    "Blend = cv2.cvtColor(S,cv2.COLOR_GRAY2RGB)\n",
    "Dodge = Target / (1-Blend)\n",
    "\n",
    "\n",
    "\n",
    "#Screen Blending: http://www.deepskycolors.com/archive/2010/04/21/formulas-for-Photoshop-blending-modes.html\n",
    "# Composite = 1 - (1-Target) * (1-Blend)\n",
    "Composite = cv2.normalize(Composite, None, alpha = 0, beta = 1, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "\n",
    "print(np.max(hls))\n",
    "# Plotting thresholded images\n",
    "f, axes = plt.subplots(3, 2, figsize=(20,10))\n",
    "axes[0,0].set_title('L Channel')\n",
    "axes[0,0].imshow(hls[:,:,0], cmap='gray')\n",
    "\n",
    "axes[0,1].set_title('L Channel Threshold')\n",
    "axes[0,1].imshow(H, cmap='gray')\n",
    "\n",
    "axes[1,0].set_title('S Channel')\n",
    "axes[1,0].imshow(hls[:,:,2], cmap='gray')\n",
    "\n",
    "axes[1,1].set_title('S Channel Threshold')\n",
    "axes[1,1].imshow(S, cmap='gray')\n",
    "\n",
    "axes[2,0].set_title('Undistorted')\n",
    "axes[2,0].imshow(undistorted)\n",
    "\n",
    "axes[2,1].set_title('Composite')\n",
    "axes[2,1].imshow(Composite, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2  # import OpenCV\n",
    "# import numpy\n",
    "# from blend_modes import dodge\n",
    "\n",
    "# # # Import background image\n",
    "# # background_img_float = cv2.imread('background.png',-1).astype(float)\n",
    "\n",
    "# # # Import foreground image\n",
    "# # foreground_img_float = cv2.imread('foreground.png',-1).astype(float)\n",
    "\n",
    "# print(np.max(Target))\n",
    "# # Blend images\n",
    "# opacity = 0.7  # The opacity of the foreground that is blended onto the background is 70 %.\n",
    "# blended_img_float = blend_modes.dodge(Target.astype(float), Blend.astype(float), opacity)\n",
    "\n",
    "# # Display blended image\n",
    "# cv2.imshow('window',blended_img_float)\n",
    "# cv2.waitKey()  # Press a key to close window with the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 720, 3)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([L,L,L]).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
